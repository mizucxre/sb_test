import logging
import httpx
from typing import List, Optional, Dict
from datetime import datetime, timedelta
import asyncio
import re

logger = logging.getLogger(__name__)

class TelegramChannelService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –∏–∑ Telegram –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ RSS"""
    
    def __init__(self):
        self.channel_url = "https://t.me/seabluushop"
        self.rss_url = "https://rss.app/feeds/6vY1Jqk7Gv5dWn9L.xml"  # –ü—Ä–∏–º–µ—Ä RSS –¥–ª—è Telegram –∫–∞–Ω–∞–ª–∞
        self.cache = []
        self.last_update = None
        
    async def get_channel_posts(self, limit: int = 5) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ RSS"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (–∫—ç—à–∏—Ä—É–µ–º –Ω–∞ 30 –º–∏–Ω—É—Ç)
        if self.cache and self.last_update and (datetime.now() - self.last_update).total_seconds() < 1800:
            return self.cache[:limit]
        
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å—Ç—ã —á–µ—Ä–µ–∑ RSS
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(self.rss_url)
                if response.status_code == 200:
                    posts = self.parse_rss_feed(response.text, limit)
                else:
                    # –ï—Å–ª–∏ RSS –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
                    posts = self.get_fallback_posts(limit)
            
            self.cache = posts
            self.last_update = datetime.now()
            return posts
            
        except Exception as e:
            logger.error(f"Error fetching Telegram channel posts: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self.get_fallback_posts(limit)
    
    def parse_rss_feed(self, rss_content: str, limit: int) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ RSS —Ñ–∏–¥–∞"""
        try:
            posts = []
            
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ RSS (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å xml.etree –∏–ª–∏ feedparser)
            items = re.findall(r'<item>(.*?)</item>', rss_content, re.DOTALL)
            
            for i, item in enumerate(items[:limit]):
                title_match = re.search(r'<title>(.*?)</title>', item)
                description_match = re.search(r'<description>(.*?)</description>', item)
                pub_date_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                
                post = {
                    "id": i + 1,
                    "title": title_match.group(1) if title_match else "–ü–æ—Å—Ç –∏–∑ SEABLUU",
                    "content": self.clean_html(description_match.group(1) if description_match else "–ù–æ–≤—ã–π –ø–æ—Å—Ç –≤ –∫–∞–Ω–∞–ª–µ"),
                    "image_url": self.extract_image_url(item),
                    "date": pub_date_match.group(1) if pub_date_match else datetime.now().isoformat(),
                    "views": 1000 + i * 100,
                    "likes": 50 + i * 10
                }
                posts.append(post)
            
            return posts
            
        except Exception as e:
            logger.error(f"Error parsing RSS feed: {e}")
            return self.get_fallback_posts(limit)
    
    def get_fallback_posts(self, limit: int) -> List[Dict]:
        """–ó–∞–≥–ª—É—à–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –¥–ª—è –∫–∞–Ω–∞–ª–∞ SEABLUU"""
        posts = [
            {
                "id": 1,
                "title": "üî• –ù–æ–≤—ã–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ SEABLUU!",
                "content": "–í –Ω–∞—à–µ–º –º–∞–≥–∞–∑–∏–Ω–µ –ø–æ—è–≤–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã –æ—Ç –≤–µ–¥—É—â–∏—Ö –±—Ä–µ–Ω–¥–æ–≤. –£—Å–ø–µ–π—Ç–µ –∑–∞–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–º–∏!",
                "image_url": "/static/images/seabluu-post-1.jpg",
                "date": (datetime.now() - timedelta(hours=2)).isoformat(),
                "views": 1250,
                "likes": 89
            },
            {
                "id": 2,
                "title": "üéâ –°–∫–∏–¥–∫–∞ 20% –Ω–∞ –≤—Å–µ –∑–∞–∫–∞–∑—ã",
                "content": "–¢–æ–ª—å–∫–æ –¥–æ –∫–æ–Ω—Ü–∞ –Ω–µ–¥–µ–ª–∏ –¥–µ–π—Å—Ç–≤—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Å–∫–∏–¥–∫–∞ –¥–ª—è –Ω–∞—à–∏—Ö –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤!",
                "image_url": "/static/images/seabluu-post-2.jpg",
                "date": (datetime.now() - timedelta(days=1)).isoformat(),
                "views": 980,
                "likes": 67
            },
            {
                "id": 3,
                "title": "üì¶ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–∫–∞–∑–æ–≤",
                "content": "–í—Å–µ –∑–∞–∫–∞–∑—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –∫–ª–∏–µ–Ω—Ç–∞–º. –°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏!",
                "image_url": "/static/images/seabluu-post-3.jpg",
                "date": (datetime.now() - timedelta(days=2)).isoformat(),
                "views": 743,
                "likes": 42
            },
            {
                "id": 4,
                "title": "üåü –û—Ç–∑—ã–≤—ã –Ω–∞—à–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤",
                "content": "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –≤—Å–µ—Ö –∑–∞ –¥–æ–≤–µ—Ä–∏–µ –∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –æ –Ω–∞—à–µ–π —Ä–∞–±–æ—Ç–µ! –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–¥–æ–≤–∞—Ç—å –≤–∞—Å!",
                "image_url": "/static/images/seabluu-post-4.jpg",
                "date": (datetime.now() - timedelta(days=3)).isoformat(),
                "views": 1120,
                "likes": 78
            },
            {
                "id": 5,
                "title": "üõí –ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –∑–∞–∫–∞–∑ –≤ SEABLUU",
                "content": "–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –∑–∞–∫–∞–∑–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤. –í—Å–µ –ø—Ä–æ—Å—Ç–æ –∏ —É–¥–æ–±–Ω–æ!",
                "image_url": "/static/images/seabluu-post-5.jpg",
                "date": (datetime.now() - timedelta(days=4)).isoformat(),
                "views": 890,
                "likes": 55
            }
        ]
        return posts[:limit]
    
    def clean_html(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ HTML —Ç–µ–≥–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        return re.sub(r'<[^>]+>', '', text).strip()
    
    def extract_image_url(self, item: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ RSS"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_match = re.search(r'<img[^>]+src="([^"]+)"', item)
        if image_match:
            return image_match.group(1)
        
        # –ó–∞–≥–ª—É—à–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        return f"/static/images/seabluu-post-{len(self.cache) % 5 + 1}.jpg"
    
    def format_post_date(self, date_str: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –ø–æ—Å—Ç–∞"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç—ã
            for fmt in ['%a, %d %b %Y %H:%M:%S %Z', '%Y-%m-%dT%H:%M:%S']:
                try:
                    date = datetime.strptime(date_str, fmt)
                    break
                except ValueError:
                    continue
            else:
                date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            
            now = datetime.now()
            diff = now - date
            
            if diff.days > 7:
                return date.strftime('%d.%m.%Y')
            elif diff.days > 0:
                return f"{diff.days} –¥–Ω. –Ω–∞–∑–∞–¥"
            elif diff.seconds > 3600:
                hours = diff.seconds // 3600
                return f"{hours} —á. –Ω–∞–∑–∞–¥"
            elif diff.seconds > 60:
                minutes = diff.seconds // 60
                return f"{minutes} –º–∏–Ω. –Ω–∞–∑–∞–¥"
            else:
                return "—Ç–æ–ª—å–∫–æ —á—Ç–æ"
        except:
            return "–Ω–µ–¥–∞–≤–Ω–æ"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
telegram_service = TelegramChannelService()
